from flask import Flask, render_template, request, session, send_file, redirect, url_for, flash, jsonify
from modules import top_earners, smart_accounts, gmgn
from utils import fetch_data, export_to_excel
import time
import datetime
import pandas as pd
import json
# æ–°å¢çš„æ¨¡å—
from modules import holder, parse_transactions, estimate_costs, cluster_addresses
import os
from modules import wallet_tag_engine
import gc
import signal

# æ•°æ®åº“ç›¸å…³å¯¼å…¥
from dotenv import load_dotenv
from config.database import init_database, get_db_config, cleanup_db_connections
from services.database_service import TopTraderService, WalletTagService, AnalysisJobService, with_long_running_session
import logging

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
app.secret_key = os.getenv('SECRET_KEY', 'your_secret_key_here')  # ä»ç¯å¢ƒå˜é‡è·å–
app.config['TEMPLATES_AUTO_RELOAD'] = True
app.config['SESSION_TYPE'] = 'filesystem'  # ä½¿ç”¨æ–‡ä»¶ç³»ç»Ÿå­˜å‚¨ä¼šè¯
app.config['SESSION_PERMANENT'] = True
app.config['PERMANENT_SESSION_LIFETIME'] = datetime.timedelta(hours=24)  # ä¼šè¯æœ‰æ•ˆæœŸ24å°æ—¶

# å°è¯•ä½¿ç”¨Flask-Sessionæ‰©å±•ï¼Œå¦‚æœå·²å®‰è£…
try:
    from flask_session import Session
    Session(app)
    logger.info("ğŸ” å·²å¯ç”¨Flask-Sessionæ‰©å±•ï¼Œä¼šè¯å°†æ›´åŠ ç¨³å®š")
except ImportError:
    logger.warning("âš ï¸ æœªå®‰è£…Flask-Sessionæ‰©å±•ï¼Œä½¿ç”¨é»˜è®¤ä¼šè¯å­˜å‚¨")
    pass

# æ•°æ®åº“åˆå§‹åŒ–
try:
    logger.info("ğŸ”„ å¼€å§‹æ•°æ®åº“åˆå§‹åŒ–...")
    db_config = init_database()
    logger.info("ğŸ¯ æ•°æ®åº“è¿æ¥æˆåŠŸï¼")
except Exception as e:
    logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
    logger.warning("âš ï¸  åº”ç”¨å°†åœ¨æ— æ•°æ®åº“æ¨¡å¼ä¸‹è¿è¡Œ")
    db_config = None

# ğŸ”§ å…è´¹ç‰ˆRenderï¼šåº”ç”¨å¯åŠ¨æ—¶è‡ªåŠ¨åˆå§‹åŒ–æ•°æ®åº“
def initialize_database_tables():
    """åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–æ•°æ®åº“è¡¨ï¼ˆå…è´¹ç‰ˆRenderé€‚é…ï¼‰"""
    if not db_config:
        logger.warning("âš ï¸  æ•°æ®åº“é…ç½®ä¸å¯ç”¨ï¼Œè·³è¿‡è¡¨åˆå§‹åŒ–")
        return False
    
    try:
        logger.info("ğŸ“‹ åˆå§‹åŒ–æ•°æ®åº“è¡¨...")
        from models.database_models import Base
        
        # åˆ›å»ºæ‰€æœ‰è¡¨
        Base.metadata.create_all(bind=db_config.get_engine())
        logger.info("âœ… æ•°æ®åº“è¡¨åˆå§‹åŒ–å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¡¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

# æ‰§è¡Œæ•°æ®åº“è¡¨åˆå§‹åŒ–
initialize_database_tables()

@app.route("/")
def index():
    """é¦–é¡µ"""
    return render_template("index.html")

# å°†ä¹‹å‰çš„debug_tradersä¿ç•™ï¼Œä½†æ”¹ä¸ºç‹¬ç«‹åŠŸèƒ½
@app.route("/debug_traders", methods=["GET", "POST"])
def debug_traders():
    """è°ƒè¯•äº¤æ˜“è€…æ•°æ®ç»“æ„"""
    if request.method == "POST":
        token_address = request.form.get("tokenAddress", "").strip()
        chain_id = request.form.get("chainId", "501").strip()
        
        try:
            from modules.top_earners import fetch_top_traders
            
            traders = fetch_top_traders(token_address, chain_id, 3)  # åªè·å–3ä¸ªè¿›è¡Œè°ƒè¯•
            
            if traders:
                import json
                debug_info = {
                    'count': len(traders),
                    'sample_trader': traders[0],
                    'all_fields': list(traders[0].keys()) if traders else []
                }
                
                return f"<pre>{json.dumps(debug_info, indent=2, ensure_ascii=False)}</pre>"
            else:
                return "æ²¡æœ‰è·å–åˆ°äº¤æ˜“è€…æ•°æ®"
                
        except Exception as e:
            import traceback
            return f"<pre>é”™è¯¯: {e}\n\n{traceback.format_exc()}</pre>"
    
    return '''
    <form method="post">
        ä»£å¸åœ°å€: <input type="text" name="tokenAddress" value="HtTYHz1Kf3rrQo6AqDLmss7gq5WrkWAaXn3tupUZbonk" style="width:400px">
        <br><br>é“¾ID: <input type="text" name="chainId" value="501">
        <br><br><input type="submit" value="è°ƒè¯•æ•°æ®ç»“æ„">
    </form>
    '''

# æ¢å¤åŸæ¥çš„top_earnersè·¯ç”±
@app.route("/top_earners", methods=["GET", "POST"])
def top_earners_view():
    chain_id = request.args.get("chainId", request.form.get("chainId", ""))
    chain_id = chain_id.strip()
    token_address = request.args.get("tokenAddress", request.form.get("tokenAddress", ""))
    token_address = token_address.strip()
    limit = request.args.get("limit", request.form.get("limit", "100"))
    try:
        limit = int(limit)
    except Exception:
        limit = 100

    if request.method == "POST" and token_address and chain_id:
        try:
            # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“ç¼“å­˜ï¼ˆå¦‚æœå¯ç”¨ä¸”æ•°æ®æ–°é²œï¼‰
            traders = []
            use_cache = os.getenv('ENABLE_DATABASE_CACHE', 'True').lower() == 'true'
            
            if use_cache and db_config:
                logger.info("ğŸ” æ£€æŸ¥æ•°æ®åº“ç¼“å­˜...")
                if TopTraderService.is_data_fresh(token_address, chain_id, max_age_hours=1):
                    traders = TopTraderService.get_traders(token_address, chain_id, limit)
                    logger.info(f"âœ… ä½¿ç”¨æ•°æ®åº“ç¼“å­˜ï¼Œè·å–åˆ° {len(traders)} ä¸ªäº¤æ˜“è€…")
            
            # å¦‚æœç¼“å­˜æ— æ•°æ®ï¼Œä»APIè·å–
            if not traders:
                logger.info("ğŸŒ ä»APIè·å–æ•°æ®...")
                traders = top_earners.fetch_top_traders(token_address, chain_id=chain_id, limit=limit)
                
                # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå¦‚æœå¯ç”¨æ•°æ®åº“ï¼‰
                if traders and db_config:
                    try:
                        TopTraderService.save_traders(traders, token_address, chain_id)
                        logger.info("ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“")
                    except Exception as e:
                        logger.warning(f"âš ï¸  ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            
            df = top_earners.prepare_traders_data(traders)
            
            # ä¿å­˜å®Œæ•´æ•°æ®åˆ°session
            session['traders_data'] = df.to_dict()
            session['token_address'] = token_address
            session['chain_id'] = chain_id
            session['limit'] = limit
            
            # ä¸ºæ˜¾ç¤ºå‡†å¤‡æ•°æ®
            if not df.empty:
                # æ·»åŠ åœ°å€è¶…é“¾æ¥
                if "walletAddress" in df.columns:
                    df["walletAddress"] = df["walletAddress"].apply(
                        lambda x: f'<a href="/address/{x}" title="{x}">{x[:5]}...{x[-5:]}</a>' if pd.notna(x) else ""
                    )
                elif "holderWalletAddress" in df.columns:
                    df["holderWalletAddress"] = df["holderWalletAddress"].apply(
                        lambda x: f'<a href="/address/{x}" title="{x}">{x[:5]}...{x[-5:]}</a>' if pd.notna(x) else ""
                    )
                
                # æ·»åŠ æµè§ˆå™¨é“¾æ¥
                if "explorerUrl" in df.columns:
                    df["explorerUrl"] = df["explorerUrl"].apply(
                        lambda x: f'<a href="{x}" target="_blank">æŸ¥çœ‹</a>' if pd.notna(x) and x else ""
                    )
                
                # æ ¼å¼åŒ–æ—¶é—´æˆ³
                if "lastTradeTime" in df.columns:
                    df["lastTradeTime"] = pd.to_datetime(df["lastTradeTime"], unit='ms', errors='coerce')
                
                # æ ¼å¼åŒ–æ•°å€¼
                numeric_columns = ['totalPnl', 'winRate', 'avgProfit', 'avgLoss', 'maxProfit', 'maxLoss']
                for col in numeric_columns:
                    if col in df.columns:
                        df[col] = pd.to_numeric(df[col], errors='coerce').round(2)
                
                # æ˜¾ç¤ºçš„å…³é”®å­—æ®µ - æ›´æ–°ä¸ºå®é™…å¯ç”¨çš„å­—æ®µ
                display_columns = [
                    "walletAddress", "totalPnl", "totalProfitPercentage", 
                    "realizedProfit", "realizedProfitPercentage",
                    "buyCount", "sellCount", "totalCount", 
                    "buyValue", "sellValue", "holdAmount",
                    "boughtAvgPrice", "soldAvgPrice",
                    "tags", "explorerUrl"
                ]
                
                # è¿‡æ»¤å‡ºå­˜åœ¨çš„åˆ—
                display_df = df[[col for col in display_columns if col in df.columns]]
                
                table_html = display_df.to_html(
                    classes="table table-hover table-bordered table-striped", 
                    index=False, 
                    escape=False,
                    render_links=True
                ) if not display_df.empty else ""
            else:
                table_html = ""
            
            return render_template(
                "top_earners.html", 
                table=table_html, 
                token=token_address, 
                chain_id=chain_id,
                limit=limit,
                record_count=len(df)
            )
        except Exception as e:
            flash(f"æŸ¥è¯¢å¤±è´¥: {str(e)}", "danger")
            return redirect(url_for('top_earners_view'))

    # sessionæ¢å¤é€»è¾‘ä¿æŒä¸å˜...
    if 'traders_data' in session and session.get('token_address') == token_address and session.get('chain_id') == chain_id and session.get('limit', 100) == limit:
        df = pd.DataFrame(session['traders_data'])
        
        if not df.empty:
            # é‡æ–°åº”ç”¨æ ¼å¼åŒ–é€»è¾‘
            display_columns = [
                "walletAddress", "holderWalletAddress", "totalPnl", "winRate",
                "winCount", "lossCount", "totalCount", "avgProfit", "avgLoss",
                "maxProfit", "maxLoss", "roi", "tags"
            ]
            
            display_df = df[[col for col in display_columns if col in df.columns]]
            
            table_html = display_df.to_html(
                classes="table table-hover table-bordered table-striped", 
                index=False, 
                escape=False,
                render_links=True
            )
            return render_template(
                "top_earners.html", 
                table=table_html, 
                token=token_address, 
                chain_id=chain_id,
                limit=limit,
                record_count=len(df)
            )
    
    return render_template("top_earners.html", token=token_address, chain_id=chain_id, limit=limit)

@app.route("/download_top_earners", methods=["GET", "POST"])
def download_top_earners():
    if request.method != "POST":
        # å¯¹äºGETè¯·æ±‚ï¼Œç›´æ¥è¿”å›404
        return "Not Found", 404

    token_address = request.form.get("tokenAddress", "").strip()
    chain_id = request.form.get("chainId", "").strip()
    limit = request.form.get("limit", "100").strip()
    try:
        limit = int(limit)
    except Exception:
        limit = 100

    if not token_address or not chain_id:
        flash("ç¼ºå°‘ä»£å¸åœ°å€æˆ–é“¾ID", "danger")
        return redirect(url_for('top_earners_view'))

    try:
        if (
            'traders_data' in session and
            session.get('token_address') == token_address and
            session.get('chain_id') == chain_id and
            session.get('limit', 100) == limit
        ):
            import pandas as pd
            df = pd.DataFrame(session['traders_data'])
        else:
            traders = top_earners.fetch_top_traders(token_address, chain_id=chain_id, limit=limit)
            df = top_earners.prepare_traders_data(traders)
        return export_to_excel(df, f"top_traders_{token_address[:10]}")
    except Exception as e:
        flash(f"å¯¼å‡ºå¤±è´¥: {str(e)}", "danger")
        return redirect(url_for('top_earners_view'))

@app.route("/address/<wallet>")
def address_detail(wallet):
    try:
        tokens = top_earners.fetch_address_token_list(wallet)
        df = top_earners.prepare_tokens_data(tokens)
        
        # ä¿å­˜å®Œæ•´æ•°æ®åˆ°session
        session['address_tokens_data'] = df.to_dict()
        session['wallet_address'] = wallet
        
        # æ·»åŠ åœ°å€è¶…é“¾æ¥
        if not df.empty and "tokenContractAddress" in df.columns:
            df["tokenContractAddress"] = df["tokenContractAddress"].apply(
                lambda x: f'<a href="/top_earners?tokenAddress={x}" title="{x}">{x[:5]}...{x[-5:]}</a>'
            )
        
        # æ·»åŠ æµè§ˆå™¨é“¾æ¥
        if not df.empty and "explorerUrl" in df.columns:
            df["explorerUrl"] = df["explorerUrl"].apply(
                lambda x: f'<a href="{x}" target="_blank">æŸ¥çœ‹</a>' if x else ""
            )
        elif not df.empty and "innerGotoUrl" in df.columns:
            df["innerGotoUrl"] = df["innerGotoUrl"].apply(
                lambda x: f'<a href="{x}" target="_blank">æŸ¥çœ‹</a>' if x else ""
            )
        
        # æ ¼å¼åŒ–æ—¶é—´æˆ³
        if not df.empty and "latestTime" in df.columns:
            df["latestTime"] = pd.to_datetime(df["latestTime"], unit='ms')
        
        # åªæ˜¾ç¤ºéƒ¨åˆ†å…³é”®å­—æ®µ
        display_columns = [
            "tokenSymbol", "tokenContractAddress", "totalPnl", "totalPnlPercentage",
            "buyVolume", "sellVolume", "balance", "balanceUsd", 
            "latestTime", "explorerUrl", "innerGotoUrl"
        ]
        
        # è¿‡æ»¤å‡ºå­˜åœ¨çš„åˆ—
        display_df = df[[col for col in display_columns if col in df.columns]]
        
        table_html = display_df.to_html(
            classes="table table-hover table-bordered table-striped", 
            index=False, 
            escape=False,
            render_links=True
        ) if not display_df.empty else ""
        
        return render_template(
            "address_detail.html", 
            wallet=wallet, 
            table=table_html, 
            error=None,
            record_count=len(df)
        )
    except Exception as e:
        return render_template("address_detail.html", wallet=wallet, table=None, error=str(e))

@app.route("/download_address_tokens", methods=["POST"])
def download_address_tokens():
    wallet_address = request.form.get("walletAddress", "").strip()
    if not wallet_address:
        flash("ç¼ºå°‘é’±åŒ…åœ°å€", "danger")
        return redirect(url_for('address_detail', wallet=wallet_address))
    
    try:
        # ä¼˜å…ˆä½¿ç”¨sessionä¸­çš„æ•°æ®
        if 'address_tokens_data' in session and session.get('wallet_address') == wallet_address:
            df = pd.DataFrame(session['address_tokens_data'])
        else:
            tokens = top_earners.fetch_address_token_list(wallet_address)
            df = top_earners.prepare_tokens_data(tokens)
        
        return export_to_excel(df, f"top_tokens_{wallet_address[:10]}")
    except Exception as e:
        flash(f"å¯¼å‡ºå¤±è´¥: {str(e)}", "danger")
        return redirect(url_for('address_detail', wallet=wallet_address))

@app.route("/smart_accounts", methods=["GET", "POST"])
def smart_accounts():
    if request.method == "POST":
        target_address = request.form.get("targetAddress", "").strip()
        chain_id = request.form.get("chainId", "501").strip()
        max_tokens = int(request.form.get("maxTokens", 50))
        page_limit = int(request.form.get("pageLimit", 5))
        
        if not target_address:
            flash("è¯·è¾“å…¥ç›®æ ‡åœ°å€", "danger")
            return render_template("smart_accounts.html")
        
        try:
            start_time = time.time()
            results = smart_accounts.find_smart_accounts(target_address, chain_id, max_tokens, page_limit)
            elapsed_time = time.time() - start_time
            
            # ä¿å­˜ç»“æœåˆ°session
            session['smart_accounts_results'] = results
            session['smart_accounts_params'] = {
                'targetAddress': target_address,
                'chainId': chain_id,
                'maxTokens': max_tokens,
                'pageLimit': page_limit
            }
            
            return render_template(
                "smart_accounts.html",
                results=results,
                target_address=target_address,
                elapsed_time=round(elapsed_time, 2),
                record_count=len(results)
            )
        except Exception as e:
            flash(f"åˆ†æå¤±è´¥: {str(e)}", "danger")
            return render_template("smart_accounts.html")
    
    # æ¢å¤ä¸Šä¸€æ¬¡çš„ç»“æœ
    if 'smart_accounts_results' in session:
        return render_template(
            "smart_accounts.html",
            results=session['smart_accounts_results'],
            target_address=session['smart_accounts_params']['targetAddress'],
            elapsed_time=0,
            record_count=len(session['smart_accounts_results'])
        )
    
    return render_template("smart_accounts.html")

@app.route("/download_smart_accounts", methods=["POST"])
def download_smart_accounts():
    if 'smart_accounts_results' not in session:
        flash("æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®", "warning")
        return redirect(url_for('smart_accounts_view'))
    
    try:
        # åˆ›å»ºDataFrame
        data = []
        for address, count in session['smart_accounts_results']:
            data.append({
                "åœ°å€": address,
                "å‡ºç°æ¬¡æ•°": count,
                "å¯ç–‘åº¦": "éå¸¸é«˜" if count > 10 else "é«˜" if count > 5 else "ä¸­" if count > 2 else "ä½"
            })
        df = pd.DataFrame(data)
        filename_prefix = f"smart_accounts_{session['smart_accounts_params']['targetAddress'][:10]}"
        return export_to_excel(df, filename_prefix)
    except Exception as e:
        flash(f"å¯¼å‡ºå¤±è´¥: {str(e)}", "danger")
        return redirect(url_for('smart_accounts'))

def merge_existing_remarks(normal_remarks, conspiracy_remarks, existing_remarks_text, merge_strategy):
    """
    åˆå¹¶å·²æœ‰å¤‡æ³¨åœ°å€å’Œæ–°ç”Ÿæˆçš„å¤‡æ³¨
    
    Args:
        normal_remarks: æ–°ç”Ÿæˆçš„æ™®é€šåœ°å€å¤‡æ³¨åˆ—è¡¨
        conspiracy_remarks: æ–°ç”Ÿæˆçš„é˜´è°‹é’±åŒ…å¤‡æ³¨åˆ—è¡¨
        existing_remarks_text: å·²æœ‰å¤‡æ³¨åœ°å€æ–‡æœ¬ï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼š
                              1. "åœ°å€:å¤‡æ³¨" æ¯è¡Œä¸€ä¸ª
                              2. JSONæ ¼å¼: [{"address": "xxx", "name": "xxx"}]
        merge_strategy: åˆå¹¶ç­–ç•¥ï¼Œ"keep_existing" æˆ– "keep_new"
    
    Returns:
        tuple: (åˆå¹¶åçš„normal_remarks, åˆå¹¶åçš„conspiracy_remarks, å†²çªåˆ—è¡¨)
    """
    conflicts = []
    existing_remarks = {}
    
    # è§£æå·²æœ‰å¤‡æ³¨åœ°å€ - æ”¯æŒå¤šç§æ ¼å¼
    existing_remarks_text = existing_remarks_text.strip()
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºJSONæ ¼å¼
    if existing_remarks_text.startswith('[') and existing_remarks_text.endswith(']'):
        try:
            # JSONæ ¼å¼è§£æ
            import json
            json_data = json.loads(existing_remarks_text)
            for item in json_data:
                if isinstance(item, dict) and 'address' in item:
                    address = item['address'].strip().lower()
                    # æ”¯æŒå¤šç§å¤‡æ³¨å­—æ®µå
                    remark = item.get('name') or item.get('remark') or item.get('label') or ''
                    if address and remark:
                        existing_remarks[address] = remark
        except json.JSONDecodeError:
            # JSONè§£æå¤±è´¥ï¼ŒæŒ‰æ™®é€šæ–‡æœ¬å¤„ç†
            pass
    
    # å¦‚æœä¸æ˜¯JSONæˆ–JSONè§£æå¤±è´¥ï¼ŒæŒ‰è¡Œè§£æ
    if not existing_remarks:
        for line in existing_remarks_text.split('\n'):
            line = line.strip()
            if not line or ':' not in line:
                continue
            
            try:
                address, remark = line.split(':', 1)
                address = address.strip().lower()  # ç»Ÿä¸€è½¬æ¢ä¸ºå°å†™
                remark = remark.strip()
                if address and remark:
                    existing_remarks[address] = remark
            except ValueError:
                continue
    
    # åˆ›å»ºæ–°å¤‡æ³¨çš„åœ°å€æ˜ å°„
    new_normal = {item['address'].lower(): item for item in normal_remarks}
    new_conspiracy = {item['address'].lower(): item for item in conspiracy_remarks}
    
    # åˆå¹¶é€»è¾‘
    merged_normal = []
    merged_conspiracy = []
    processed_addresses = set()
    
    # å¤„ç†å·²æœ‰å¤‡æ³¨
    for address, existing_remark in existing_remarks.items():
        processed_addresses.add(address)
        
        # æ£€æŸ¥æ˜¯å¦åœ¨æ–°å¤‡æ³¨ä¸­æœ‰å†²çª
        conflict_item = None
        new_remark = None
        is_conspiracy = False
        
        if address in new_normal:
            conflict_item = new_normal[address]
            new_remark = conflict_item['remark']
        elif address in new_conspiracy:
            conflict_item = new_conspiracy[address]
            new_remark = conflict_item['remark']
            is_conspiracy = True
        
        if conflict_item and new_remark != existing_remark:
            # æœ‰å†²çªï¼Œè®°å½•å†²çªä¿¡æ¯è®©ç”¨æˆ·æ‰‹åŠ¨é€‰æ‹©
            conflicts.append({
                'address': conflict_item['address'],  # ä¿æŒåŸå§‹å¤§å°å†™
                'existing_remark': existing_remark,
                'new_remark': new_remark,
                'is_conspiracy': is_conspiracy
            })
            
            # å†²çªçš„åœ°å€æš‚æ—¶ä¸æ·»åŠ åˆ°ç»“æœä¸­ï¼Œç­‰ç”¨æˆ·é€‰æ‹©åå†å¤„ç†
            # è¿™æ ·ç¡®ä¿ç”¨æˆ·å¯ä»¥æ‰‹åŠ¨é€‰æ‹©æ¯ä¸ªå†²çªåœ°å€çš„å¤‡æ³¨
                
        elif conflict_item:
            # æ²¡æœ‰å†²çªï¼Œå¤‡æ³¨ç›¸åŒï¼Œç›´æ¥ä½¿ç”¨
            if is_conspiracy:
                merged_conspiracy.append(conflict_item)
            else:
                merged_normal.append(conflict_item)
        else:
            # å·²æœ‰å¤‡æ³¨ä½†æ–°å¤‡æ³¨ä¸­æ²¡æœ‰è¿™ä¸ªåœ°å€ï¼Œç›´æ¥æ·»åŠ åˆ°æ™®é€šå¤‡æ³¨
            merged_normal.append({
                'address': address.upper(),  # æ¢å¤åŸå§‹æ ¼å¼
                'remark': existing_remark
            })
    
    # æ·»åŠ æ–°å¤‡æ³¨ä¸­æ²¡æœ‰å†²çªçš„åœ°å€
    for address, item in new_normal.items():
        if address not in processed_addresses:
            merged_normal.append(item)
    
    for address, item in new_conspiracy.items():
        if address not in processed_addresses:
            merged_conspiracy.append(item)
    
    return merged_normal, merged_conspiracy, conflicts

@app.route("/download_gmgn_remarks", methods=["POST"])
def download_gmgn_remarks():
    """ä¸‹è½½GMGNå¤‡æ³¨æ•°æ®"""
    if 'gmgn_results' not in session:
        flash("æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®", "warning")
        return redirect(url_for('gmgn_tool'))
    
    remark_type = request.form.get("remarkType", "all")  # all, normal, conspiracy
    export_format = request.form.get("exportFormat", "excel")  # excel, txt
    
    try:
        results = session['gmgn_results']
        normal_remarks = results.get('normal_remarks', [])
        conspiracy_remarks = results.get('conspiracy_remarks', [])
        params = results.get('params', {})
        
        # æ ¹æ®ç±»å‹å‡†å¤‡æ•°æ®
        data_to_export = []
        
        if remark_type == "all":
            data_to_export.extend(normal_remarks)
            data_to_export.extend(conspiracy_remarks)
        elif remark_type == "normal":
            data_to_export = normal_remarks
        elif remark_type == "conspiracy":
            data_to_export = conspiracy_remarks
        
        if not data_to_export:
            flash("æ²¡æœ‰æ•°æ®å¯å¯¼å‡º", "warning")
            return redirect(url_for('gmgn_tool'))
        
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(data_to_export)
        df.index = df.index + 1  # ä»1å¼€å§‹ç¼–å·
        
        # æ·»åŠ å…ƒæ•°æ®
        ca_name = params.get('ca_name', 'Unknown')
        timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
        
        if export_format == "txt":
            # å¯¼å‡ºä¸ºæ–‡æœ¬æ ¼å¼ (åœ°å€:å¤‡æ³¨)
            filename = f"gmgn_remarks_{ca_name}_{remark_type}_{timestamp}.txt"
            content = "\n".join([f"{item['address']}:{item['remark']}" for item in data_to_export])
            
            import io
            output = io.StringIO()
            output.write(content)
            output.seek(0)
            
            from flask import Response
            return Response(
                output.getvalue(),
                mimetype="text/plain",
                headers={"Content-disposition": f"attachment; filename={filename}"}
            )
        else:
            # å¯¼å‡ºä¸ºExcelæ ¼å¼
            filename_prefix = f"gmgn_remarks_{ca_name}_{remark_type}_{timestamp}"
            return export_to_excel(df, filename_prefix)
            
    except Exception as e:
        flash(f"å¯¼å‡ºå¤±è´¥: {str(e)}", "danger")
        return redirect(url_for('gmgn_tool'))

@app.route("/gmgn", methods=["GET", "POST"])
def gmgn_tool():
    normal_remarks = None
    conspiracy_remarks = None
    
    if request.method == "POST":
        ca_address = request.form.get("caAddress", "").strip()
        ca_name = request.form.get("caName", "").strip()
        chain_id = request.form.get("chainId", "501").strip()
        
        # è·å–æ•°é‡å‚æ•°
        holder_count = request.form.get("holderCount", "50")
        trader_count = request.form.get("traderCount", "50")
        
        # é˜´è°‹é’±åŒ…æ£€æµ‹å‚æ•°
        conspiracy_check = request.form.get("conspiracyCheck") == "on"
        conspiracy_days = request.form.get("conspiracyDays", "10")
        
        # å·²æœ‰å¤‡æ³¨åœ°å€å’Œåˆå¹¶ç­–ç•¥
        existing_remarks_text = request.form.get("existingRemarks", "").strip()
        merge_strategy = request.form.get("mergeStrategy", "keep_existing")
        
        try:
            holder_count = max(1, min(200, int(holder_count)))
        except ValueError:
            holder_count = 50
            
        try:
            trader_count = max(1, min(200, int(trader_count)))
        except ValueError:
            trader_count = 50
            
        try:
            conspiracy_days = max(1, min(30, int(conspiracy_days)))
        except ValueError:
            conspiracy_days = 10
        
        if not ca_address or not ca_name:
            flash("è¯·è¾“å…¥CAåœ°å€ä»¥åŠåç§°", "danger")
            return render_template("gmgn.html")
            
        try:
            print(f"ğŸ¯ å¼€å§‹è·å–å¤‡æ³¨æ•°æ®...")
            print(f"ğŸ“Š Holdersæ•°é‡: {holder_count}, Tradersæ•°é‡: {trader_count}")
            print(f"ğŸ” é˜´è°‹é’±åŒ…æ£€æµ‹: {'å¯ç”¨' if conspiracy_check else 'å…³é—­'}")
            
            # ä½¿ç”¨æ–°çš„ç”Ÿæˆå‡½æ•°ï¼Œæ”¯æŒå¤šé“¾
            result = gmgn.generate_address_remarks(
                ca_address, 
                ca_name, 
                holder_count, 
                trader_count,
                conspiracy_check,
                conspiracy_days,
                chain_id  # ğŸ”§ ä¼ é€’é“¾IDå‚æ•°
            )
            
            normal_remarks = result.get("normal_remarks", [])
            conspiracy_remarks = result.get("conspiracy_remarks", [])
            
            # å¤„ç†å·²æœ‰å¤‡æ³¨åœ°å€çš„åˆå¹¶
            if existing_remarks_text:
                normal_remarks, conspiracy_remarks, conflicts = merge_existing_remarks(
                    normal_remarks, conspiracy_remarks, existing_remarks_text, merge_strategy
                )
                
                if conflicts:
                    # å¦‚æœæœ‰å†²çªï¼Œå°†å†²çªä¿¡æ¯ä¼ é€’ç»™å‰ç«¯
                    session['address_conflicts'] = conflicts
                    flash(f"å‘ç° {len(conflicts)} ä¸ªåœ°å€å¤‡æ³¨å†²çªï¼Œè¯·æ‰‹åŠ¨é€‰æ‹©", "warning")
            
            print(f"ğŸ‰ å¤‡æ³¨æ•°æ®ç”Ÿæˆå®Œæˆ!")
            print(f"ğŸ“Š æ™®é€šåœ°å€: {len(normal_remarks)} ä¸ª")
            print(f"ğŸŸ é˜´è°‹é’±åŒ…: {len(conspiracy_remarks)} ä¸ª")
            
            # ä¿å­˜ç»“æœåˆ°session
            session['gmgn_results'] = {
                'normal_remarks': normal_remarks,
                'conspiracy_remarks': conspiracy_remarks,
                'params': {
                    'ca_address': ca_address,
                    'ca_name': ca_name,
                    'chain_id': chain_id,  # ğŸ”§ ä¿å­˜é“¾ID
                    'holder_count': holder_count,
                    'trader_count': trader_count,
                    'conspiracy_check': conspiracy_check,
                    'conspiracy_days': conspiracy_days
                }
            }
            
            if conspiracy_check:
                flash(f"åˆ†æå®Œæˆï¼æ™®é€šåœ°å€ {len(normal_remarks)} ä¸ªï¼Œé˜´è°‹é’±åŒ… {len(conspiracy_remarks)} ä¸ª", "success")
            else:
                flash(f"åˆ†æå®Œæˆï¼å…±ç”Ÿæˆ {len(normal_remarks)} ä¸ªåœ°å€å¤‡æ³¨", "success")
            
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            flash(f"æŸ¥è¯¢å¤±è´¥: {str(e)}", "danger")
    
    return render_template("gmgn.html", 
                         normal_remarks=normal_remarks,
                         conspiracy_remarks=conspiracy_remarks)

@app.route("/resolve_conflicts", methods=["POST"])
def resolve_conflicts():
    """å¤„ç†åœ°å€å¤‡æ³¨å†²çª"""
    if 'address_conflicts' not in session or 'gmgn_results' not in session:
        flash("æ²¡æœ‰å¾…å¤„ç†çš„å†²çª", "warning")
        return redirect(url_for('gmgn_tool'))
    
    try:
        conflicts = session['address_conflicts']
        results = session['gmgn_results']
        normal_remarks = results.get('normal_remarks', [])
        conspiracy_remarks = results.get('conspiracy_remarks', [])
        
        # æ ¹æ®ç”¨æˆ·é€‰æ‹©å¤„ç†å†²çªåœ°å€
        for i, conflict in enumerate(conflicts):
            choice = request.form.get(f"conflict_{i}")
            if choice == "existing":
                final_remark = conflict['existing_remark']
            else:  # choice == "new"
                final_remark = conflict['new_remark']
            
            # åˆ›å»ºè§£å†³åçš„åœ°å€é¡¹
            resolved_item = {
                'address': conflict['address'],
                'remark': final_remark
            }
            
            # æ·»åŠ åˆ°ç›¸åº”åˆ—è¡¨
            if conflict['is_conspiracy']:
                conspiracy_remarks.append(resolved_item)
            else:
                normal_remarks.append(resolved_item)
        
        # æ›´æ–°sessionä¸­çš„ç»“æœ
        session['gmgn_results']['normal_remarks'] = normal_remarks
        session['gmgn_results']['conspiracy_remarks'] = conspiracy_remarks
        
        # æ¸…é™¤å†²çªä¿¡æ¯
        if 'address_conflicts' in session:
            del session['address_conflicts']
        
        flash("å†²çªå·²è§£å†³", "success")
        
    except Exception as e:
        flash(f"å¤„ç†å†²çªæ—¶å‡ºé”™: {str(e)}", "danger")
    
    return redirect(url_for('gmgn_tool'))

@app.route("/ignore_conflicts", methods=["POST"])
def ignore_conflicts():
    """å¿½ç•¥åœ°å€å¤‡æ³¨å†²çª"""
    if 'address_conflicts' in session:
        del session['address_conflicts']
        flash("å·²å¿½ç•¥å†²çª", "info")
    return redirect(url_for('gmgn_tool'))

# æ–°å¢çš„è·¯ç”±
@app.route("/solana_analysis", methods=["GET", "POST"])
def solana_analysis():
    if request.method == "POST":
        token_address = request.form.get("tokenAddress", "").strip()
        chain_id = request.form.get("chainId", "501").strip()
        top_n = int(request.form.get("topN", 50))
        helius_api_key = request.form.get("heliusApiKey", "").strip()
        token_id = request.form.get("tokenId", "").strip()  # CoinGecko token ID
        
        if not token_address:
            flash("è¯·è¾“å…¥Tokenåœ°å€", "danger")
            return render_template("solana_analysis.html")
        
        try:
            # æ­¥éª¤1: è·å–Top Holders
            print("æ­£åœ¨è·å–Top Holders...")
            timestamp = int(time.time() * 1000)
            holders_df = holder.get_all_holders(chain_id, token_address, timestamp, top_n)
            
            if holders_df.empty:
                flash("æœªæ‰¾åˆ°æŒä»“æ•°æ®", "warning")
                return render_template("solana_analysis.html")
            
            # ä¿å­˜åŸºç¡€æ•°æ®
            session['solana_holders'] = holders_df.to_dict()
            session['solana_params'] = {
                'tokenAddress': token_address,
                'chainId': chain_id,
                'topN': top_n,
                'tokenId': token_id
            }
            
            results = {
                'holders_count': len(holders_df),
                'total_percentage': holders_df['percentage'].sum()
            }
            
            # æ­¥éª¤2: è§£æäº¤æ˜“ï¼ˆå¦‚æœæä¾›äº†Helius APIå¯†é’¥ï¼‰
            if helius_api_key:
                print("æ­£åœ¨è§£æäº¤æ˜“...")
                events_df = parse_transactions.batch_analyze_holders(
                    holders_df, helius_api_key, token_address
                )
                
                if not events_df.empty:
                    session['solana_events'] = events_df.to_dict()
                    results['transactions_count'] = len(events_df)
                    results['unique_addresses'] = events_df['address'].nunique()
                    
                    # æ­¥éª¤3: æˆæœ¬ä¼°ç®—ï¼ˆå¦‚æœæä¾›äº†CoinGecko token IDï¼‰
                    if token_id:
                        print("æ­£åœ¨ä¼°ç®—æˆæœ¬...")
                        pnl_df = estimate_costs.analyze_holder_profitability(
                            holders_df, events_df, token_id
                        )
                        
                        if not pnl_df.empty:
                            session['solana_pnl'] = pnl_df.to_dict()
                            results['avg_multiplier'] = pnl_df['multiplier'].mean()
                            results['profitable_addresses'] = (pnl_df['unrealized_pnl_usd'] > 0).sum()
                    
                    # æ­¥éª¤4: èšç±»åˆ†æ
                    print("æ­£åœ¨è¿›è¡Œèšç±»åˆ†æ...")
                    output_dir = os.path.join('static', 'temp')
                    cluster_results = cluster_addresses.full_cluster_analysis(
                        events_df, holders_df, output_dir
                    )
                    
                    if cluster_results:
                        session['solana_clusters'] = {
                            k: v.to_dict() if hasattr(v, 'to_dict') else v 
                            for k, v in cluster_results.items()
                        }
                        
                        if 'transfer_stats' in cluster_results:
                            results['cluster_count'] = len(cluster_results['transfer_stats'])
            
            return render_template("solana_analysis.html", results=results)
            
        except Exception as e:
            flash(f"åˆ†æå¤±è´¥: {str(e)}", "danger")
            return render_template("solana_analysis.html")
    
    return render_template("solana_analysis.html")

@app.route("/download_solana_data/<data_type>")
def download_solana_data(data_type):
    """ä¸‹è½½Solanaåˆ†ææ•°æ®"""
    try:
        if data_type == 'holders' and 'solana_holders' in session:
            df = pd.DataFrame(session['solana_holders'])
            return export_to_excel(df, f"solana_holders_{int(time.time())}")
        
        elif data_type == 'events' and 'solana_events' in session:
            df = pd.DataFrame(session['solana_events'])
            return export_to_excel(df, f"solana_events_{int(time.time())}")
        
        elif data_type == 'pnl' and 'solana_pnl' in session:
            df = pd.DataFrame(session['solana_pnl'])
            return export_to_excel(df, f"solana_pnl_{int(time.time())}")
        
        elif data_type == 'clusters' and 'solana_clusters' in session:
            cluster_data = session['solana_clusters']
            if 'transfer_clusters' in cluster_data:
                df = pd.DataFrame(cluster_data['transfer_clusters'])
                return export_to_excel(df, f"solana_clusters_{int(time.time())}")
        
        flash("æ•°æ®ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ", "warning")
        return redirect(url_for('solana_analysis'))
        
    except Exception as e:
        flash(f"ä¸‹è½½å¤±è´¥: {str(e)}", "danger")
        return redirect(url_for('solana_analysis'))

@app.route("/holder_snapshots", methods=["GET", "POST"])
def holder_snapshots():
    """åŸºäºå®šæ—¶é‡‡é›†æ•°æ®çš„æŒä»“å¿«ç…§åˆ†æ"""
    from modules.holder import list_collection_tasks, analyze_holder_patterns
    
    # è·å–æ‰€æœ‰é‡‡é›†ä»»åŠ¡
    tasks = list_collection_tasks()
    
    if request.method == "POST":
        task_id = request.form.get("task_id")
        top_n = int(request.form.get("top_n", 100))
        min_snapshots = int(request.form.get("min_snapshots", 3))
        
        if not task_id:
            flash("è¯·é€‰æ‹©ä¸€ä¸ªé‡‡é›†ä»»åŠ¡", "danger")
            return render_template("holder_snapshots.html", tasks=tasks)
        
        try:
            # åˆ†ææŒä»“æ¨¡å¼
            analysis_result = analyze_holder_patterns(task_id, top_n, min_snapshots)
            
            return render_template(
                "holder_snapshots.html",
                tasks=tasks,
                analysis_result=analysis_result,
                task_id=task_id,
                top_n=top_n,
                min_snapshots=min_snapshots
            )
            
        except Exception as e:
            flash(f"åˆ†æå¤±è´¥: {e}", "danger")
            return render_template("holder_snapshots.html", tasks=tasks)
    
    return render_template("holder_snapshots.html", tasks=tasks)

def cleanup_old_snapshot_files():
    """æ¸…ç†è¿‡æœŸçš„å¿«ç…§ä¸´æ—¶æ–‡ä»¶"""
    import tempfile
    import os
    import glob
    import time
    
    # è·å–ä¸´æ—¶ç›®å½•
    temp_dir = os.path.join(tempfile.gettempdir(), 'okx_pnl_tool')
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    if not os.path.exists(temp_dir):
        return
        
    # å¯»æ‰¾æ‰€æœ‰å¿«ç…§æ–‡ä»¶
    snapshot_files = glob.glob(os.path.join(temp_dir, 'snapshot_*.pkl'))
    
    # æ£€æŸ¥æ¯ä¸ªæ–‡ä»¶
    now = time.time()
    for file_path in snapshot_files:
        # å¦‚æœæ–‡ä»¶è¶…è¿‡12å°æ—¶æœªä¿®æ”¹ï¼Œåˆ™åˆ é™¤
        if os.path.exists(file_path) and (now - os.path.getmtime(file_path)) > 12 * 3600:
            try:
                os.remove(file_path)
                logger.info(f"å·²æ¸…ç†è¿‡æœŸå¿«ç…§æ–‡ä»¶: {file_path}")
            except Exception as e:
                logger.error(f"æ¸…ç†å¿«ç…§æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {str(e)}")

@app.route('/download_holder_snapshots', methods=["POST"])
def download_holder_snapshots():
    """ä¸‹è½½æŒä»“å¿«ç…§æ•°æ®"""
    # æ¸…ç†è€æ—§æ–‡ä»¶
    cleanup_old_snapshot_files()
    if 'holder_snapshots' not in session:
        flash("æ²¡æœ‰å¯å¯¼å‡ºçš„å¿«ç…§æ•°æ®", "warning")
        return redirect(url_for('holder_snapshots'))
    
    try:
        # è·å–ä¸´æ—¶æ–‡ä»¶è·¯å¾„ä¸å½“å‰è¯·æ±‚çš„ä»£å¸åœ°å€
        snapshot_info = session['holder_snapshots']
        temp_file = snapshot_info.get('temp_file')
        session_token_address = snapshot_info.get('token_address')
        current_token_address = request.form.get('tokenAddress')  # ä»è¡¨å•è·å–å½“å‰æŸ¥è¯¢çš„ä»£å¸åœ°å€
        
        # æ—¥å¿—è®°å½•
        if current_token_address:
            logger.info(f"å½“å‰è¯·æ±‚å¯¼å‡ºä»£å¸: {current_token_address}")
            logger.info(f"Sessionä¸­ä¿å­˜çš„ä»£å¸: {session_token_address}")
            
            # å¦‚æœè¡¨å•ä¸­æä¾›äº†ä»£å¸åœ°å€ï¼Œä¸”ä¸sessionä¸­ä¸ä¸€è‡´ï¼Œè¯´æ˜ç”¨æˆ·å·²ç»æŸ¥è¯¢äº†æ–°çš„ä»£å¸
            if session_token_address != current_token_address:
                flash(f"æ£€æµ‹åˆ°ä»£å¸åœ°å€å˜æ›´ï¼Œè¯·å…ˆæŸ¥è¯¢æ–°ä»£å¸çš„å¿«ç…§æ•°æ®åå†å¯¼å‡º", "warning")
                return redirect(url_for('holder_snapshots'))
        
        if not temp_file or not os.path.exists(temp_file):
            flash("å¿«ç…§æ•°æ®å·²è¿‡æœŸæˆ–ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°ç”Ÿæˆ", "warning")
            return redirect(url_for('holder_snapshots'))
        
        # ä»ä¸´æ—¶æ–‡ä»¶åŠ è½½æ•°æ®
        import pickle
        with open(temp_file, 'rb') as f:
            try:
                snapshot_data = pickle.load(f)
                historical_data = snapshot_data['data']
                token_address = snapshot_data['token_address']
            except Exception as e:
                flash(f"æ— æ³•åŠ è½½å¿«ç…§æ•°æ®: {str(e)}", "danger")
                return redirect(url_for('holder_snapshots'))
        
        export_type = request.form.get("exportType", "merged")  # merged, timeseries, all
        
        # è°ƒç”¨å¯¼å‡ºå‡½æ•°
        from modules.holder import export_holder_snapshots
                # æ·»åŠ æ›´å¤šæ—¥å¿—
        logger.info(f"æ­£åœ¨å¯¼å‡ºå¿«ç…§æ•°æ®ï¼Œç±»å‹: {export_type}, å¿«ç…§æ•°é‡: {len(historical_data)}")
        logger.info(f"å¯¼å‡ºä»£å¸åœ°å€: {token_address}")
        
        # å¯¹æ¯ä¸ªå¿«ç…§æ—¶é—´ç‚¹è®°å½•æ•°æ®é‡
        for label, df in historical_data.items():
            if isinstance(df, pd.DataFrame):
                logger.info(f"æ—¶é—´ç‚¹ {label}: {len(df)} æ¡è®°å½•")
            else:
                logger.info(f"æ—¶é—´ç‚¹ {label}: éDataFrameç±»å‹ ({type(df)})")
        
        # è°ƒç”¨å¯¼å‡ºå‡½æ•°
        merged_path, timeseries_path = export_holder_snapshots(historical_data, token_address)        # è®°å½•å¯¼å‡ºç»“æœ
        if merged_path:
            logger.info(f"åˆå¹¶CSVå¯¼å‡ºæˆåŠŸ: {merged_path}")
        else:
            logger.warning("åˆå¹¶CSVå¯¼å‡ºå¤±è´¥")
            
        if timeseries_path:
            logger.info(f"æ—¶åºCSVå¯¼å‡ºæˆåŠŸ: {timeseries_path}")
        else:
            logger.warning("æ—¶åºCSVå¯¼å‡ºå¤±è´¥")
        
        if export_type == "timeseries" and timeseries_path:
            # è¿”å›æ—¶é—´åºåˆ—æ ¼å¼
            try:
                return send_file(
                    timeseries_path,
                    as_attachment=True,
                    download_name=os.path.basename(timeseries_path),
                    mimetype="text/csv"
                )
            except Exception as e:
                logger.error(f"æ–‡ä»¶å‘é€å¤±è´¥: {str(e)}")
                flash(f"æ–‡ä»¶ä¸‹è½½å¤±è´¥: {str(e)}", "danger")
                return redirect(url_for('holder_snapshots'))
        elif export_type == "all":
            # æ‰“åŒ…ä¸¤ä¸ªæ–‡ä»¶
            import zipfile
            from io import BytesIO
            
            memory_file = BytesIO()
            with zipfile.ZipFile(memory_file, 'w') as zf:
                if merged_path:
                    zf.write(merged_path, os.path.basename(merged_path))
                if timeseries_path:
                    zf.write(timeseries_path, os.path.basename(timeseries_path))
            
            memory_file.seek(0)
            return send_file(
                memory_file,
                as_attachment=True,
                download_name=f"holder_snapshots_{token_address[:8]}_{int(time.time())}.zip",
                mimetype="application/zip"
            )
        else:
            # é»˜è®¤è¿”å›åˆå¹¶æ ¼å¼
            if merged_path:
                try:
                    return send_file(
                        merged_path,
                        as_attachment=True,
                        download_name=os.path.basename(merged_path),
                        mimetype="text/csv"
                    )
                except Exception as e:
                    logger.error(f"æ–‡ä»¶å‘é€å¤±è´¥: {str(e)}")
                    flash(f"æ–‡ä»¶ä¸‹è½½å¤±è´¥: {str(e)}", "danger")
                    return redirect(url_for('holder_snapshots'))
        
        flash("å¯¼å‡ºå¤±è´¥: æœªç”Ÿæˆå¯ä¸‹è½½çš„æ–‡ä»¶", "danger")
        logger.error("å¯¼å‡ºå¤±è´¥: æœªç”Ÿæˆå¯ä¸‹è½½çš„æ–‡ä»¶")
        return redirect(url_for('holder_snapshots'))
        
    except Exception as e:
        flash(f"å¯¼å‡ºå¤±è´¥: {str(e)}", "danger")
        return redirect(url_for('holder_snapshots'))

@app.route("/whale_flow")
def whale_flow():
    """åº„å®¶èµ„é‡‘æµåŠ¨ - å¾…å¼€å‘"""
    return render_template("coming_soon.html", 
                         feature_name="åº„å®¶èµ„é‡‘æµåŠ¨",
                         description="è¿½è¸ªå¤§æˆ·èµ„é‡‘è¿›å‡ºï¼Œåˆ†æå¸‚åœºæ“æ§è¡Œä¸ºå’Œèµ„é‡‘æµå‘",
                         expected_features=[
                             "å¤§é¢è½¬è´¦å®æ—¶ç›‘æ§",
                             "èµ„é‡‘æµå‘å¯è§†åŒ–",
                             "å¼‚å¸¸äº¤æ˜“é¢„è­¦",
                             "åº„å®¶è¡Œä¸ºåˆ†æ"
                         ])

@app.route("/address_monitor")
def address_monitor():
    """åœ°å€å®æ—¶ç›‘æ§ - å¾…å¼€å‘"""
    return render_template("coming_soon.html",
                         feature_name="åœ°å€å®æ—¶ç›‘æ§", 
                         description="å®æ—¶ç›‘æ§é‡è¦åœ°å€çš„äº¤æ˜“æ´»åŠ¨ï¼ŒåŠæ—¶è·å–æŠ•èµ„ä¿¡å·",
                         expected_features=[
                             "å¤šåœ°å€æ‰¹é‡ç›‘æ§",
                             "äº¤æ˜“å®æ—¶æ¨é€",
                             "è‡ªå®šä¹‰ç›‘æ§è§„åˆ™",
                             "å†å²è¡Œä¸ºåˆ†æ"
                         ])

@app.route("/wallet_analyzer", methods=["GET", "POST"])
def wallet_analyzer():
    """é’±åŒ…æ™ºèƒ½åˆ†æå™¨ - æ”¯æŒæ‰¹é‡åœ°å€å’Œå¤‡æ³¨å¤„ç†"""
    if request.method == "POST":
        wallet_addresses_text = request.form.get("walletAddresses", "").strip()
        chain_id = request.form.get("chainId", "501")
        preserve_remarks = request.form.get("preserveRemarks", "append")  # append, prepend, replace, ignore
        
        if not wallet_addresses_text:
            flash("è¯·è¾“å…¥é’±åŒ…åœ°å€", "danger")
            return render_template("wallet_analyzer.html")
        
        # ğŸ”§ è§£æåœ°å€åˆ—è¡¨ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        addresses_with_remarks = []
        
        # æ”¯æŒé€—å·åˆ†éš”æˆ–æ¢è¡Œåˆ†éš”
        if ',' in wallet_addresses_text and '\n' not in wallet_addresses_text:
            # é€—å·åˆ†éš”æ ¼å¼ï¼š0x...:å¤‡æ³¨,0x...:å¤‡æ³¨
            entries = wallet_addresses_text.split(',')
        else:
            # æ¢è¡Œåˆ†éš”æ ¼å¼
            entries = wallet_addresses_text.split('\n')
        
        for entry in entries:
            entry = entry.strip()
            if not entry or len(entry) < 20:
                continue
                
            # è§£ææ ¼å¼ï¼šåœ°å€:å¤‡æ³¨ æˆ– çº¯åœ°å€
            if ':' in entry:
                parts = entry.split(':', 1)
                address = parts[0].strip()
                original_remark = parts[1].strip() if len(parts) > 1 else ""
            else:
                address = entry.strip()
                original_remark = ""
            
            # åŸºæœ¬åœ°å€éªŒè¯ï¼ˆETHå’ŒSolanaåœ°å€é•¿åº¦æ£€æŸ¥ï¼‰
            if len(address) >= 32:  # æ”¯æŒETH(42)å’ŒSolana(32-44)åœ°å€
                addresses_with_remarks.append({
                    'address': address,
                    'original_remark': original_remark
                })
        
        if not addresses_with_remarks:
            flash("æœªæ‰¾åˆ°æœ‰æ•ˆçš„é’±åŒ…åœ°å€", "danger")
            return render_template("wallet_analyzer.html")
        
        # ğŸ”§ é™åˆ¶æœ€å¤š100ä¸ªåœ°å€
        if len(addresses_with_remarks) > 100:
            flash(f"æœ€å¤šæ”¯æŒ100ä¸ªåœ°å€åŒæ—¶åˆ†æï¼Œå·²æˆªå–å‰100ä¸ª", "warning")
            addresses_with_remarks = addresses_with_remarks[:100]
        
        try:
            # ä½¿ç”¨æ ‡ç­¾å¼•æ“
            engine = wallet_tag_engine.WalletTagEngine()
            
            # åªæå–åœ°å€è¿›è¡Œåˆ†æ
            addresses = [item['address'] for item in addresses_with_remarks]
            print(f"ğŸ” å¼€å§‹æ‰¹é‡åˆ†æ {len(addresses)} ä¸ªé’±åŒ…...")
            results = engine.batch_analyze(addresses, chain_id)
            
            # ğŸ”§ å¤„ç†åŸå§‹å¤‡æ³¨å’Œæ–°ç”Ÿæˆçš„æ ‡ç­¾
            for i, result in enumerate(results):
                if i < len(addresses_with_remarks):
                    original_remark = addresses_with_remarks[i]['original_remark']
                    generated_tags = result.get('tags', '')
                    
                    # æ ¹æ®ç”¨æˆ·é€‰æ‹©å¤„ç†å¤‡æ³¨
                    if preserve_remarks == "replace":
                        # è¦†ç›–ï¼šåªä½¿ç”¨ç”Ÿæˆçš„æ ‡ç­¾
                        final_remark = generated_tags
                    elif preserve_remarks == "prepend":
                        # å‰é¢ï¼šåŸå§‹å¤‡æ³¨ + ç”Ÿæˆçš„æ ‡ç­¾
                        if original_remark and generated_tags:
                            final_remark = f"{original_remark} | {generated_tags}"
                        else:
                            final_remark = original_remark or generated_tags
                    elif preserve_remarks == "ignore":
                        # å¿½ç•¥ï¼šåªä¿ç•™åŸå§‹å¤‡æ³¨
                        final_remark = original_remark
                    else:  # append (é»˜è®¤)
                        # åé¢ï¼šç”Ÿæˆçš„æ ‡ç­¾ + åŸå§‹å¤‡æ³¨
                        if generated_tags and original_remark:
                            final_remark = f"{generated_tags} | {original_remark}"
                        else:
                            final_remark = generated_tags or original_remark
                    
                    result['original_remark'] = original_remark
                    result['final_remark'] = final_remark
                    result['generated_tags'] = generated_tags
                else:
                    result['original_remark'] = ""
                    result['final_remark'] = result.get('tags', '')
                    result['generated_tags'] = result.get('tags', '')
            
            # ä¿å­˜ç»“æœåˆ°session
            session['wallet_analyzer_results'] = results
            session['wallet_analyzer_params'] = {
                'addresses': addresses,
                'chain_id': chain_id,
                'preserve_remarks': preserve_remarks,
                'total_count': len(addresses)
            }
            
            flash(f"åˆ†æå®Œæˆï¼æˆåŠŸåˆ†æäº† {len(results)} ä¸ªé’±åŒ…", "success")
            
            return render_template("wallet_analyzer.html", 
                                 results=results,
                                 chain_id=chain_id,
                                 wallet_addresses=wallet_addresses_text,
                                 preserve_remarks=preserve_remarks)
            
        except Exception as e:
            print(f"âŒ åˆ†æå¼‚å¸¸: {e}")
            import traceback
            print(f"ğŸ“ å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            
            # ğŸ”§ å¦‚æœæ˜¯æ•°æ®åº“è¿æ¥é—®é¢˜ï¼Œæ¸…ç†è¿æ¥æ± 
            if e and "connection" in str(e).lower():
                cleanup_db_connections()
                
            flash(f"åˆ†æå¤±è´¥: {str(e)}", "danger")
            return render_template("wallet_analyzer.html")
    
    return render_template("wallet_analyzer.html")

@app.route("/smart_wallet", methods=["GET", "POST"])
def smart_wallet():
    """æ™ºèƒ½é’±åŒ…åˆ†æ - é‡å®šå‘åˆ°æ–°åˆ†æå™¨"""
    return redirect(url_for('wallet_analyzer'))

@app.route('/get_top_profit', methods=['POST'])
def get_top_profit():
    """è·å– TOP ç›ˆåˆ©åœ°å€ - ç§»é™¤æ•°é‡é™åˆ¶"""
    try:
        data = request.get_json()
        token_address = data.get('token_address', '').strip()
        chain_id = data.get('chain_id', '501')
        # ç§»é™¤æ•°é‡é™åˆ¶ï¼Œå…è®¸ç”¨æˆ·é€‰æ‹©çš„å€¼
        limit = int(data.get('limit', 50))
        
        # åªå¯¹æç«¯å€¼åšåˆç†é™åˆ¶
        if limit > 1000:
            limit = 1000
        elif limit < 1:
            limit = 50
        
        if not token_address:
            return jsonify({'error': 'ä»£å¸åœ°å€ä¸èƒ½ä¸ºç©º'}), 400
        
        print(f"ğŸ” å¼€å§‹æŸ¥è¯¢ä»£å¸ {token_address[:8]}... çš„ç›ˆåˆ©åœ°å€ï¼Œæ•°é‡: {limit}")
        
        # æ ¹æ®æŸ¥è¯¢æ•°é‡è°ƒæ•´è¶…æ—¶æ—¶é—´
        if limit <= 50:
            timeout_seconds = 22
        elif limit <= 100:
            timeout_seconds = 28
        elif limit <= 200:
            timeout_seconds = 35
        else:
            timeout_seconds = 45  # å¤§é‡æŸ¥è¯¢éœ€è¦æ›´é•¿æ—¶é—´
        
        # è®¾ç½®åŠ¨æ€è¶…æ—¶ä¿æŠ¤
        def timeout_handler(signum, frame):
            raise TimeoutError("æŸ¥è¯¢è¶…æ—¶")
        
        signal.signal(signal.SIGALRM, timeout_handler)
        signal.alarm(timeout_seconds)
        
        try:
            # ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„æ•°é‡
            traders = fetch_top_traders(token_address, chain_id, limit)
            
            if not traders:
                signal.alarm(0)
                return jsonify({
                    'error': 'æœªæ‰¾åˆ°è¯¥ä»£å¸çš„ç›ˆåˆ©åœ°å€æ•°æ®',
                    'success': False
                }), 404
            
            # å¤„ç†æ•°æ®
            df = prepare_traders_data(traders)
            
            if df.empty:
                signal.alarm(0)
                return jsonify({
                    'error': 'æ•°æ®å¤„ç†å¤±è´¥',
                    'success': False
                }), 500
            
            # è½¬æ¢ä¸ºJSONæ ¼å¼
            result_data = []
            for _, row in df.head(limit).iterrows():
                result_data.append({
                    'address': row['walletAddress'],
                    'pnl': float(row['totalPnl']),
                    'roi': float(row['roi']),
                    'buy_count': int(row['buyCount']),
                    'sell_count': int(row['sellCount']),
                    'win_rate': float(row['winRate']),
                    'tags': row['tags'],
                    'rank': int(row['rank'])
                })
            
            signal.alarm(0)
            
            # æ‰‹åŠ¨åƒåœ¾å›æ”¶
            del traders, df
            gc.collect()
            
            return jsonify({
                'success': True,
                'data': result_data,
                'total': len(result_data),
                'message': f'æˆåŠŸè·å– {len(result_data)} ä¸ªç›ˆåˆ©åœ°å€'
            })
            
        except TimeoutError:
            signal.alarm(0)
            return jsonify({
                'error': f'æŸ¥è¯¢è¶…æ—¶ï¼ˆ{timeout_seconds}ç§’ï¼‰ï¼Œè¯·å°è¯•å‡å°‘æŸ¥è¯¢æ•°é‡',
                'success': False
            }), 408
            
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢ç›ˆåˆ©åœ°å€å¤±è´¥: {e}")
        return jsonify({
            'error': f'æŸ¥è¯¢å¤±è´¥: {str(e)}',
            'success': False
        }), 500
    finally:
        # ç¡®ä¿æ¸…ç†å†…å­˜
        gc.collect()

# æ·»åŠ ç³»ç»Ÿç›‘æ§è·¯ç”±
@app.route('/system_status')
def system_status():
    """ç³»ç»ŸçŠ¶æ€ç›‘æ§ - åŒ…å«è¿æ¥æ± çŠ¶æ€"""
    try:
        import psutil
        import os
        from services.database_service import get_connection_pool_status
        
        # è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        
        # æ•°æ®åº“è¿æ¥æµ‹è¯•
        db_status = "connected" if db_config and db_config.test_connection() else "disconnected"
        
        # ğŸ”§ è·å–è¿æ¥æ± çŠ¶æ€
        pool_status = get_connection_pool_status() if db_config else {}
        
        return jsonify({
            'memory_usage_mb': memory_info.rss / 1024 / 1024,
            'memory_percent': process.memory_percent(),
            'database_status': db_status,
            'connection_pool': pool_status,  # æ–°å¢è¿æ¥æ± ä¿¡æ¯
            'status': 'healthy'
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'error': str(e)
        })

@app.route('/db_test')
def db_test():
    """æ•°æ®åº“è¿æ¥æµ‹è¯•"""
    if not db_config:
        return jsonify({
            'status': 'error',
            'message': 'æ•°æ®åº“é…ç½®æœªåˆå§‹åŒ–'
        }), 500
    
    try:
        # æµ‹è¯•è¿æ¥
        is_connected = db_config.test_connection()
        
        if is_connected:
            # è·å–æ•°æ®åº“ä¿¡æ¯
            with db_config.get_session() as session:
                from sqlalchemy import text
                result = session.execute(text("""
                    SELECT 
                        current_database() as database_name,
                        current_user as user_name,
                        version() as version
                """))
                db_info = result.fetchone()
            
            return jsonify({
                'status': 'success',
                'message': 'æ•°æ®åº“è¿æ¥æ­£å¸¸',
                'database_name': db_info.database_name,
                'user_name': db_info.user_name,
                'version': db_info.version.split(' ')[0:2]  # åªæ˜¾ç¤ºPostgreSQLç‰ˆæœ¬
            })
        else:
            return jsonify({
                'status': 'error',
                'message': 'æ•°æ®åº“è¿æ¥å¤±è´¥'
            }), 500
            
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'æ•°æ®åº“æµ‹è¯•å¤±è´¥: {str(e)}'
        }), 500

@app.route("/fund_flow_analysis", methods=["GET", "POST"])
def fund_flow_analysis():
    """èµ„é‡‘æµåˆ†æ - é›†æˆæ¥æºåˆ†æã€èšç±»å’Œå¯è§†åŒ–"""
    if request.method == "POST":
        try:
            # å¤„ç†ä¸Šä¼ çš„CSVæ–‡ä»¶
            uploaded_file = request.files.get('tx_file')
            if not uploaded_file or uploaded_file.filename == '':
                flash("è¯·ä¸Šä¼ äº¤æ˜“æ•°æ®CSVæ–‡ä»¶", "warning")
                return render_template("fund_flow_analysis.html")
            
            # è¯»å–CSVæ•°æ®
            df = pd.read_csv(uploaded_file)
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ['from_address', 'to_address', 'value']
            missing_fields = [field for field in required_fields if field not in df.columns]
            if missing_fields:
                flash(f"CSVæ–‡ä»¶ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}", "danger")
                return render_template("fund_flow_analysis.html")
            
            # è·å–åœ°å€æ ‡æ³¨
            known_sources_text = request.form.get("knownSources", "").strip()
            chart_style = request.form.get("chart_style", "refined")  # è·å–å›¾è¡¨æ ·å¼é€‰æ‹©
            known_sources = {}
            if known_sources_text:
                for line in known_sources_text.split('\n'):
                    if ',' in line:
                        addr, label = line.split(',', 1)
                        known_sources[addr.strip()] = label.strip()
            
            # èµ„é‡‘æ¥æºåˆ†æ
            from modules.source_analysis import SourceAnalyzer
            analyzer = SourceAnalyzer(df)
            labeled_df = analyzer.label_sources(known_sources)
            source_stats = analyzer.aggregate_sources()
            
            # Sankeyå›¾ç”Ÿæˆ - æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„æ ·å¼
            sankey_html = 'static/temp_sankey.html'
            if chart_style == "network":
                from modules.sankey_viz import plot_network_flow
                plot_network_flow(
                    df, 
                    title="èµ„é‡‘æµå‘ç½‘ç»œå›¾",
                    output_path=sankey_html,
                    address_labels=known_sources, 
                    top_n=15
                )
            elif chart_style == "standard":
                from modules.sankey_viz import plot_sankey_standard
                plot_sankey_standard(
                    df, 
                    title="èµ„é‡‘æµå‘åˆ†æ (æ ‡å‡†çº¿æ¡)",
                    output_path=sankey_html,
                    address_labels=known_sources, 
                    top_n=15
                )
            else:  # refined ç²¾ç»†æ ·å¼
                from modules.sankey_viz import plot_sankey
                plot_sankey(
                    df, 
                    title="èµ„é‡‘æµå‘åˆ†æ (ç²¾ç»†çº¿æ¡)",
                    output_path=sankey_html,
                    address_labels=known_sources, 
                    top_n=15
                )
            
            # åœ°å€èšç±»åˆ†æï¼ˆå¦‚æœæœ‰tx_hashå­—æ®µï¼‰
            cluster_results = {}
            if 'tx_hash' in df.columns:
                from modules.cluster_addresses import build_transfer_graph, cluster_addresses, analyze_clusters
                from modules.cluster_addresses import co_spend_cluster_analysis
                
                # è½¬è´¦å…³ç³»èšç±»
                transfer_graph = build_transfer_graph(df)
                if transfer_graph.number_of_nodes() > 0:
                    transfer_clusters = cluster_addresses(transfer_graph)
                    cluster_df, cluster_stats = analyze_clusters(transfer_clusters, pd.DataFrame())
                    cluster_results['transfer'] = {
                        'cluster_count': len(cluster_stats),
                        'stats': cluster_stats.to_dict('records')
                    }
                
                # Co-spendåˆ†æ
                try:
                    co_spend_df, co_spend_stats = co_spend_cluster_analysis(df, pd.DataFrame())
                    if co_spend_stats is not None:
                        cluster_results['co_spend'] = {
                            'cluster_count': len(co_spend_stats),
                            'stats': co_spend_stats.to_dict('records')
                        }
                except Exception as e:
                    logger.warning(f"Co-spendåˆ†æå¤±è´¥: {str(e)}")
            
            # ä¿å­˜ç»“æœåˆ°sessionï¼ˆè½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹ä»¥æ”¯æŒJSONåºåˆ—åŒ–ï¼‰
            session['fund_flow_results'] = {
                'source_stats': source_stats.to_dict('records'),
                'cluster_results': cluster_results,
                'sankey_path': sankey_html,
                'total_transactions': int(len(df)),
                'unique_addresses': int(len(set(df['from_address']) | set(df['to_address']))),
                'total_value': float(df['value'].sum())
            }
            
            flash(f"åˆ†æå®Œæˆï¼å…±å¤„ç† {len(df)} ç¬”äº¤æ˜“", "success")
            
            return render_template("fund_flow_analysis.html", 
                                 source_stats=source_stats.to_dict('records'),
                                 cluster_results=cluster_results,
                                 sankey_available=True,
                                 total_transactions=len(df),
                                 unique_addresses=len(set(df['from_address']) | set(df['to_address'])),
                                 total_value=df['value'].sum())
            
        except Exception as e:
            flash(f"åˆ†æå¤±è´¥: {str(e)}", "danger")
            logger.error(f"èµ„é‡‘æµåˆ†æé”™è¯¯: {str(e)}")
            return render_template("fund_flow_analysis.html")
    
    return render_template("fund_flow_analysis.html")

@app.route("/view_sankey")
def view_sankey():
    """æŸ¥çœ‹Sankeyå›¾"""
    sankey_path = session.get('fund_flow_results', {}).get('sankey_path')
    if sankey_path and os.path.exists(sankey_path):
        return send_file(sankey_path)
    else:
        flash("Sankeyå›¾ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ‰§è¡Œåˆ†æ", "warning")
        return redirect(url_for('fund_flow_analysis'))

# ğŸ”§ åº”ç”¨å…³é—­æ—¶æ¸…ç†èµ„æº
@app.teardown_appcontext
def cleanup_db_context(error):
    """åº”ç”¨ä¸Šä¸‹æ–‡æ¸…ç†æ—¶ï¼Œç¡®ä¿æ•°æ®åº“è¿æ¥è¢«æ­£ç¡®å…³é—­"""
    try:
        if db_config:
            # æ¸…ç†scoped_session
            db_config.SessionLocal.remove()
    except Exception as e:
        logger.error(f"âŒ æ¸…ç†æ•°æ®åº“ä¸Šä¸‹æ–‡å¤±è´¥: {e}")

# ğŸ”§ å®šæœŸæ¸…ç†è¿æ¥æ± ï¼ˆå¯é€‰ï¼‰
@app.route('/cleanup_connections', methods=['POST'])
def cleanup_connections():
    """æ‰‹åŠ¨æ¸…ç†æ•°æ®åº“è¿æ¥æ± """
    try:
        if db_config:
            cleanup_db_connections()
            return jsonify({
                'status': 'success',
                'message': 'è¿æ¥æ± æ¸…ç†å®Œæˆ'
            })
        else:
            return jsonify({
                'status': 'error',
                'message': 'æ•°æ®åº“æœªåˆå§‹åŒ–'
            }), 500
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'æ¸…ç†å¤±è´¥: {str(e)}'
        }), 500


# ===================== Holderæ•°æ®é‡‡é›†ç®¡ç† =====================
@app.route("/holder_collection")
def holder_collection():
    """Holderæ•°æ®é‡‡é›†ç®¡ç†ç•Œé¢"""
    try:
        from modules.holder import list_collection_tasks
        tasks = list_collection_tasks()
        return render_template("holder_collection.html", tasks=tasks)
    except Exception as e:
        flash(f"åŠ è½½é‡‡é›†ä»»åŠ¡å¤±è´¥: {e}", "danger")
        return render_template("holder_collection.html", tasks=[])

@app.route("/holder_collection/add", methods=["POST"])
def add_holder_task():
    """æ·»åŠ æ–°çš„é‡‡é›†ä»»åŠ¡"""
    try:
        from modules.holder import create_collection_task
        
        task_id = request.form.get('task_id', '').strip()
        token_address = request.form.get('token_address', '').strip()
        token_symbol = request.form.get('token_symbol', '').strip()
        chain = request.form.get('chain', '').strip()
        interval_hours = int(request.form.get('interval_hours', 24))
        max_records = int(request.form.get('max_records', 1000))
        description = request.form.get('description', '').strip()
        
        if not all([task_id, token_address, token_symbol, chain]):
            flash("è¯·å¡«å†™æ‰€æœ‰å¿…éœ€å­—æ®µ", "warning")
            return redirect(url_for('holder_collection'))
        
        success = create_collection_task(
            task_id=task_id,
            token_address=token_address,
            token_symbol=token_symbol,
            chain=chain,
            interval_hours=interval_hours,
            max_records=max_records,
            description=description
        )
        
        if success:
            flash(f"æˆåŠŸåˆ›å»ºé‡‡é›†ä»»åŠ¡: {task_id}", "success")
        else:
            flash(f"åˆ›å»ºé‡‡é›†ä»»åŠ¡å¤±è´¥ï¼Œä»»åŠ¡å¯èƒ½å·²å­˜åœ¨", "danger")
            
    except Exception as e:
        flash(f"åˆ›å»ºä»»åŠ¡å¤±è´¥: {e}", "danger")
    
    return redirect(url_for('holder_collection'))

@app.route("/holder_collection/pause/<task_id>", methods=["POST"])
def pause_holder_task(task_id):
    """æš‚åœé‡‡é›†ä»»åŠ¡"""
    try:
        from modules.holder import pause_collection_task
        success = pause_collection_task(task_id)
        if success:
            flash(f"ä»»åŠ¡ {task_id} å·²æš‚åœ", "info")
        else:
            flash(f"æš‚åœä»»åŠ¡å¤±è´¥", "danger")
    except Exception as e:
        flash(f"æ“ä½œå¤±è´¥: {e}", "danger")
    
    return redirect(url_for('holder_collection'))

@app.route("/holder_collection/resume/<task_id>", methods=["POST"])
def resume_holder_task(task_id):
    """æ¢å¤é‡‡é›†ä»»åŠ¡"""
    try:
        from modules.holder import resume_collection_task
        success = resume_collection_task(task_id)
        if success:
            flash(f"ä»»åŠ¡ {task_id} å·²æ¢å¤", "success")
        else:
            flash(f"æ¢å¤ä»»åŠ¡å¤±è´¥", "danger")
    except Exception as e:
        flash(f"æ“ä½œå¤±è´¥: {e}", "danger")
    
    return redirect(url_for('holder_collection'))

@app.route("/holder_collection/remove/<task_id>", methods=["POST"])
def remove_holder_task(task_id):
    """åˆ é™¤é‡‡é›†ä»»åŠ¡"""
    try:
        from modules.holder import remove_collection_task
        success = remove_collection_task(task_id)
        if success:
            flash(f"ä»»åŠ¡ {task_id} å·²åˆ é™¤", "info")
        else:
            flash(f"åˆ é™¤ä»»åŠ¡å¤±è´¥", "danger")
    except Exception as e:
        flash(f"æ“ä½œå¤±è´¥: {e}", "danger")
    
    return redirect(url_for('holder_collection'))

@app.route("/holder_collection/run/<task_id>", methods=["POST"])
def run_holder_task_now(task_id):
    """ç«‹å³æ‰§è¡Œé‡‡é›†ä»»åŠ¡"""
    try:
        from modules.holder import run_task_now
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡
        import threading
        def run_task():
            run_task_now(task_id)
        
        thread = threading.Thread(target=run_task)
        thread.daemon = True
        thread.start()
        
        flash(f"ä»»åŠ¡ {task_id} å·²å¼€å§‹æ‰§è¡Œ", "info")
    except Exception as e:
        flash(f"æ‰§è¡Œä»»åŠ¡å¤±è´¥: {e}", "danger")
    
    return redirect(url_for('holder_collection'))

@app.route("/holder_collection/data")
def view_all_holder_data():
    """æŸ¥çœ‹æ‰€æœ‰é‡‡é›†æ•°æ®æ¦‚è§ˆ"""
    try:
        from modules.holder import get_all_tasks_summary
        
        tasks_summary = get_all_tasks_summary()
        
        return render_template("holder_data.html", 
                             tasks_summary=tasks_summary)
    
    except Exception as e:
        flash(f"è·å–æ•°æ®å¤±è´¥: {e}", "danger")
        return redirect(url_for('holder_collection'))

@app.route("/holder_collection/data/<task_id>")
def view_holder_data(task_id):
    """æŸ¥çœ‹é‡‡é›†æ•°æ®"""
    try:
        from modules.holder import get_task_data
        
        limit = int(request.args.get('limit', 200))
        data = get_task_data(task_id, limit)
        
        # æŒ‰æ—¶é—´åˆ†ç»„æ•°æ®
        snapshots_by_time = {}
        for record in data:
            snapshot_time = record['snapshot_time']
            if snapshot_time not in snapshots_by_time:
                snapshots_by_time[snapshot_time] = []
            snapshots_by_time[snapshot_time].append(record)
        
        return render_template("holder_data.html", 
                             task_id=task_id, 
                             snapshots_by_time=snapshots_by_time,
                             total_records=len(data))
    
    except Exception as e:
        flash(f"è·å–æ•°æ®å¤±è´¥: {e}", "danger")
        return redirect(url_for('holder_collection'))

@app.route("/holder_collection/export/<task_id>")
def export_holder_data(task_id):
    """å¯¼å‡ºé‡‡é›†æ•°æ®"""
    try:
        from modules.holder import export_task_data_csv
        
        csv_path = export_task_data_csv(task_id)
        if csv_path and os.path.exists(csv_path):
            return send_file(csv_path, as_attachment=True, 
                           download_name=f"holder_data_{task_id}.csv")
        else:
            flash("å¯¼å‡ºå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•", "danger")
            return redirect(url_for('holder_collection'))
    
    except Exception as e:
        flash(f"å¯¼å‡ºå¤±è´¥: {e}", "danger")
        return redirect(url_for('holder_collection'))

@app.route("/holder_collection/start_service", methods=["POST"])
def start_holder_service():
    """å¯åŠ¨é‡‡é›†æœåŠ¡"""
    try:
        from modules.holder import start_collection_service
        start_collection_service()
        flash("é‡‡é›†æœåŠ¡å·²å¯åŠ¨", "success")
    except Exception as e:
        flash(f"å¯åŠ¨æœåŠ¡å¤±è´¥: {e}", "danger")
    
    return redirect(url_for('holder_collection'))

@app.route("/holder_collection/stop_service", methods=["POST"])
def stop_holder_service():
    """åœæ­¢é‡‡é›†æœåŠ¡"""
    try:
        from modules.holder import stop_collection_service
        stop_collection_service()
        flash("é‡‡é›†æœåŠ¡å·²åœæ­¢", "info")
    except Exception as e:
        flash(f"åœæ­¢æœåŠ¡å¤±è´¥: {e}", "danger")
    
    return redirect(url_for('holder_collection'))


if __name__ == "__main__":
    # è·å–ç«¯å£ï¼ˆRenderä¼šæä¾›PORTç¯å¢ƒå˜é‡ï¼‰
    port = int(os.getenv('PORT', 5000))
    debug = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'
    
    logger.info(f"ğŸŒ å¯åŠ¨Flaskåº”ç”¨ï¼Œç«¯å£: {port}")
    app.run(debug=debug, host="0.0.0.0", port=port)